{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving comments for video ID 9QWEbkeT-ag: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=9QWEbkeT-ag&maxResults=10&key=AIzaSyBCkoiCjVlWEqKXxPXyRN_IjweChVmlOTA&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.', 'domain': 'youtube.commentThread', 'reason': 'videoNotFound', 'location': 'videoId', 'locationType': 'parameter'}]\">\n",
      "No valid items found for video ID 9QWEbkeT-ag\n",
      "No valid items found for video ID 9QWEbkeT-ag\n",
      "Error retrieving comments for video ID Ko19LE0F9no: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=Ko19LE0F9no&maxResults=10&key=AIzaSyBCkoiCjVlWEqKXxPXyRN_IjweChVmlOTA&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.', 'domain': 'youtube.commentThread', 'reason': 'commentsDisabled', 'location': 'videoId', 'locationType': 'parameter'}]\">\n",
      "1. Bunnies TV with an average comment sentiment of 0.6627333333333333\n",
      "Top 10 creators most similar to sentiment comment score of top 1:\n",
      "1. Visual Studio Code with an average sentiment of 0.6291500000000001\n",
      "2. Run That with an average sentiment of 0.59025\n",
      "3. LongAR15 with an average sentiment of 0.52595\n",
      "4. Cjay011 with an average sentiment of 0.44603000000000004\n",
      "5. Codr Kai with an average sentiment of 0.43620000000000003\n",
      "6. Samuel Chan with an average sentiment of 0.38667999999999997\n",
      "7. Tech Projects with an average sentiment of 0.3705\n",
      "8. Analytics with Adam with an average sentiment of 0.36807\n",
      "9. Huy NG with an average sentiment of 0.3556888888888889\n",
      "10. Vlog Creations with an average sentiment of 0.3388222222222222\n",
      "\n",
      "\n",
      "1. Code With Antonio with an average description sentiment of 0.9942\n",
      "\n",
      "Top 10 creators most similar to top 1 sentiment description score:\n",
      "1. Huy NG with an average sentiment of 0.9934\n",
      "2. n00b_asaurus with an average sentiment of 0.9893\n",
      "3. MMG with an average sentiment of 0.9889\n",
      "4. ProgrammingKnowledge with an average sentiment of 0.9863\n",
      "5. Run That with an average sentiment of 0.9839\n",
      "6. Tech Projects with an average sentiment of 0.9822\n",
      "7. James Briggs with an average sentiment of 0.973\n",
      "8. JoebobFN with an average sentiment of 0.972\n",
      "9. PLDtv with an average sentiment of 0.9709\n",
      "10. Samuel Chan with an average sentiment of 0.9564\n",
      "\n",
      "\n",
      "1. Jake Paul with an average tags similarity score of 1.0000000000000002\n",
      "\n",
      "Top 10 creators most similar to top 1 tags score:\n",
      "1. Kai Cenat Live with an average similarity of 0.9077217937441774\n",
      "2. IShowSpeed with an average similarity of 0.8\n",
      "3. Visual Studio Code with an average similarity of 0.6317988906086547\n",
      "4. Zemie with an average similarity of 0.5489873579992355\n",
      "5. Bunnies TV with an average similarity of 0.5023287782256718\n",
      "6. julien 2 with an average similarity of 0.494682513782111\n",
      "7. Myth with an average similarity of 0.48391847343256256\n",
      "8. PLDtv with an average similarity of 0.44943641652398214\n",
      "9. House of Highlights with an average similarity of 0.39943950178236076\n",
      "10. Reasonable Shorts with an average similarity of 0.3952459070505019\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from urllib.parse import unquote\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = \"AIzaSyBCkoiCjVlWEqKXxPXyRN_IjweChVmlOTA\"\n",
    "file_path = \"watch-history.json\"\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def extract_video_id(link):\n",
    "    match = re.search(r\"v=([a-zA-Z0-9_-]+)\", link)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def read_video_data_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        watch_history = json.load(file)\n",
    "\n",
    "    video_data_list = []\n",
    "    for entry in watch_history:\n",
    "        video_data = {\n",
    "            \"header\": entry.get(\"header\", \"\"),\n",
    "            \"title\": entry.get(\"title\", \"\"),\n",
    "            \"titleUrl\": entry.get(\"titleUrl\", \"\"),\n",
    "            \"subtitles\": entry.get(\"subtitles\", []),\n",
    "            \"time\": entry.get(\"time\", \"\"),\n",
    "            \"products\": entry.get(\"products\", []),\n",
    "            \"activityControls\": entry.get(\"activityControls\", [])\n",
    "        }\n",
    "        video_data_list.append(video_data)\n",
    "    return video_data_list\n",
    "\n",
    "def get_video_comments(video_id):\n",
    "    youtube = build(api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
    "    try:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=10\n",
    "        )\n",
    "        response = request.execute()\n",
    "        comments = [item['snippet']['topLevelComment']['snippet']['textDisplay'] for item in response.get('items', [])]\n",
    "        return comments\n",
    "    except HttpError as e:\n",
    "        print(f\"Error retrieving comments for video ID {video_id}: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_video_description(video_id):\n",
    "    youtube = build(api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
    "    try:\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet\",\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        if 'items' in response and response['items'] and len(response['items']) > 0:\n",
    "            description = response['items'][0]['snippet'].get('description', '')\n",
    "            return description\n",
    "        else:\n",
    "            print(f\"No valid items found for video ID {video_id}\")\n",
    "            return ''\n",
    "    except HttpError as e:\n",
    "        print(f\"Error retrieving description for video ID {video_id}: {e}\")\n",
    "        return ''\n",
    "\n",
    "def get_video_tags(video_id):\n",
    "    youtube = build(api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
    "    try:\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet\",\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        if 'items' in response and response['items'] and len(response['items']) > 0:\n",
    "            tags = response['items'][0]['snippet'].get('tags', [])\n",
    "            return tags\n",
    "        else:\n",
    "            print(f\"No valid items found for video ID {video_id}\")\n",
    "            return []\n",
    "    except HttpError as e:\n",
    "        print(f\"Error retrieving tags for video ID {video_id}: {e}\")\n",
    "        return []\n",
    "\n",
    "video_data_list = read_video_data_from_file(file_path)\n",
    "video_ids = [extract_video_id(unquote(video_data.get(\"titleUrl\", \"\"))) for video_data in video_data_list[:500] if extract_video_id(unquote(video_data.get(\"titleUrl\", \"\")))]\n",
    "\n",
    "# Group video IDs by creator\n",
    "video_ids_by_creator = {}\n",
    "for video_data, video_id in zip(video_data_list[:1000], video_ids):\n",
    "    creator_name = video_data[\"subtitles\"][0][\"name\"] if video_data[\"subtitles\"] else \"Unknown\"\n",
    "    if creator_name not in video_ids_by_creator:\n",
    "        video_ids_by_creator[creator_name] = []\n",
    "    video_ids_by_creator[creator_name].append(video_id)\n",
    "\n",
    "creators_sentiment_comments = {}\n",
    "creators_sentiment_description = {}\n",
    "creators_similarity_tags = {}\n",
    "\n",
    "for creator, creator_video_ids in video_ids_by_creator.items():\n",
    "    total_sentiment_comments = 0\n",
    "    total_comments = 0\n",
    "    total_sentiment_description = 0\n",
    "    total_similarity_tags = 0\n",
    "    total_videos = len(creator_video_ids)\n",
    "\n",
    "    for video_id in creator_video_ids:\n",
    "        # Sentiment analysis for comments\n",
    "        comments = get_video_comments(video_id)\n",
    "        for comment in comments:\n",
    "            sentiment_score = sia.polarity_scores(comment)\n",
    "            total_sentiment_comments += sentiment_score['compound']\n",
    "            total_comments += 1\n",
    "\n",
    "        # Sentiment analysis for video description\n",
    "        description = get_video_description(video_id)\n",
    "        sentiment_score_description = sia.polarity_scores(description)\n",
    "        total_sentiment_description += sentiment_score_description['compound']\n",
    "\n",
    "        # Similarity calculation for video tags\n",
    "        tags = get_video_tags(video_id)\n",
    "        if tags:\n",
    "            tags_str = ' '.join(tags)\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            tfidf_matrix = vectorizer.fit_transform([tags_str, creator])\n",
    "            similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "            total_similarity_tags += similarity[0][0]\n",
    "\n",
    "    average_sentiment_comments = total_sentiment_comments / total_comments if total_comments > 0 else 0\n",
    "    creators_sentiment_comments[creator] = average_sentiment_comments\n",
    "    average_sentiment_description = total_sentiment_description / total_videos\n",
    "    creators_sentiment_description[creator] = average_sentiment_description\n",
    "    average_similarity_tags = total_similarity_tags / total_videos\n",
    "    creators_similarity_tags[creator] = average_similarity_tags\n",
    "\n",
    "# Display the top creator and the top 10 similar creators for all outputs\n",
    "sorted_creators_comments = sorted(creators_sentiment_comments.items(), key=lambda x: x[1], reverse=True)\n",
    "print(f\"1. {sorted_creators_comments[0][0]} with an average comment sentiment of {sorted_creators_comments[0][1]}\")\n",
    "\n",
    "print(\"Top 10 creators most similar to sentiment comment score of top 1:\")\n",
    "for i, (creator, sentiment) in enumerate(sorted_creators_comments[1:11]):\n",
    "    print(f\"{i + 1}. {creator} with an average sentiment of {sentiment}\")\n",
    "print('\\n')\n",
    "\n",
    "sorted_creators_description = sorted(creators_sentiment_description.items(), key=lambda x: x[1], reverse=True)\n",
    "print(f\"1. {sorted_creators_description[0][0]} with an average description sentiment of {sorted_creators_description[0][1]}\")\n",
    "\n",
    "print(\"\\nTop 10 creators most similar to top 1 sentiment description score:\")\n",
    "for i, (creator, sentiment) in enumerate(sorted_creators_description[1:11]):\n",
    "    print(f\"{i + 1}. {creator} with an average sentiment of {sentiment}\")\n",
    "print('\\n')\n",
    "\n",
    "sorted_creators_similarity_tags = sorted(creators_similarity_tags.items(), key=lambda x: x[1], reverse=True)\n",
    "print(f\"1. {sorted_creators_similarity_tags[0][0]} with an average tags similarity score of {sorted_creators_similarity_tags[0][1]}\")\n",
    "\n",
    "print(\"\\nTop 10 creators most similar to top 1 tags score:\")\n",
    "for i, (creator, similarity) in enumerate(sorted_creators_similarity_tags[1:11]):\n",
    "    print(f\"{i + 1}. {creator} with an average similarity of {similarity}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
